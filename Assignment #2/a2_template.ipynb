{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS 481 Assignment 2: Images and Filters\n",
    "\n",
    "### Author 1\n",
    "### Author 2\n",
    "\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Load the file 'mandrill.png' using matplotlib and perform some basic manipulations on it. For each of these, display the original and the altered image side-by-side with no rescaling of the pixel size. You can use the helper function in the template. \n",
    "\n",
    "a. Create a 10-pixel wide vertical black line through the middle of the image by replacing data values in the image with zeroes. Display the original and the altered image side-by-side.\n",
    "\n",
    "b. Transpose the original image. Display the original and the altered image side-by-side.\n",
    "    \n",
    "c. \"Posterize\" the original image by reducing the number of different color levels in each channel from 256 to 2. In other words, reduce the precision in the data values in each color channel (R,G,B) so they assume only the value 0 or 1, and no values in between. Display the original and the altered image side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load standard libraries for numerical methods and plotting.\n",
    "# This same block will start almost every assignment in PHYS 481.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline  # This line is necessary to display plots inline in some Jupyter notebooks\n",
    "\n",
    "# Helper function for this assignment\n",
    "def display_img(img1,img2=None):\n",
    "    \"\"\"\n",
    "    Display 1 or 2 RGB or RGBA images in matplotlib format side-by-side inline in Jupyter.\n",
    "    For 1 image, call with only one parameter.\n",
    "    Disable any resizing of the images; show them at the exact resolution of the image without rescaling the pixel size.\n",
    "    \"\"\"\n",
    "    dpi = matplotlib.rcParams['figure.dpi']  # dots per inch of the device\n",
    "    height = img1.shape[0]\n",
    "    width = img1.shape[1]\n",
    "    if img2 is None:   # Only one figure provided\n",
    "        figsize = width / float(dpi), height / float(dpi)\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(img1)\n",
    "    else:                # 2 Figures provided\n",
    "        height=np.max([height,img2.shape[0]])\n",
    "        width=width+img2.shape[1]\n",
    "        figsize = width / float(dpi), height / float(dpi)\n",
    "        f, ax=plt.subplots(1,2,figsize=figsize)\n",
    "        ax[0].imshow(img1)\n",
    "        ax[1].imshow(img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1a():\n",
    "    \"\"\"\n",
    "    docstring goes here\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "q1a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1b():\n",
    "    \"\"\"\n",
    "    docstring goes here\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "q1b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1c():\n",
    "    \"\"\"\n",
    "    docstring goes here\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "q1c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------\n",
    "\n",
    "### Question 2\n",
    "\n",
    "To rotate an $n$-row, $m$-column image by an angle $\\theta$ in the anticlockwise direction, pixel location $[i,j]$ in the rotated (new) image corresponds to pixel location $[x,y]$ in the original image, where\n",
    "\n",
    "$$ x = (i-n/2)\\cos(\\theta)+(j-m/2)\\sin(\\theta)+n/2 $$\n",
    "\n",
    "$$ y= -(i-n/2)\\sin(\\theta)+(j-m/2)\\cos(\\theta)+m/2 $$\n",
    "\n",
    "With a few notes:\n",
    "\n",
    "1. If $[x,y]$ falls outside the range of the original image (which happens on the edges of the rotated image), a fill color should used. Please use black for this assignment.\n",
    "2. The values of $x$ and $y$ will generally be non-integer, so this rotation requires evaluation of the image data at locations that are not exactly on pixel centers in the original image. In other words, some sort of interpolation scheme is required. For this assignment, please simply round to the nearest integer. This is known as \"nearest neighbor\" interpolation. Bi-linear interpolation or other interpolation schemes are also sometimes used, but just take the simple nearest neighbor for this assignment.\n",
    "\n",
    "a. Load the mandrill image and rotate it 20 degrees anticlockwise using the equations above implemented in a nested loop. Include all the calculations (even the trig functions) in the loop. Time the execution using %timeit. Plot the original and rotated images.\n",
    "\n",
    "b. Repeat question 2a, but pull the trig functions and anything else you can pre-calculate outside the loops and rotate the original image 20 degrees clockwise.\n",
    "\n",
    "c. Repeat question 2b, but use Just-In-Time compilation and rotate 30 degrees anticlockwise.\n",
    "\n",
    "d. Repeat question 2a, but use PIL (Python Image Library) to perform the rotation and rotate 30 degrees clockwise.\n",
    "\n",
    "e. Prepare a table of how long each method took. In a few sentences, comment on the speed of the various methods and why you think there was such a difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Question 2a\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def rotate_nested_loops_JIT(img,angle):\n",
    "    \"\"\"\n",
    "    docstring goes here\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Question 2c\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def rotate_PIL(image, angle):\n",
    "    \"\"\"\n",
    "    docstring goes here\n",
    "    \"\"\"\n",
    "\n",
    "# Question 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table and comments for question 2e go here. You can use Markdown for tables like this:\n",
    "\n",
    "| Method | Time Taken (seconds) | Comments |\n",
    "|--------|----------------------|----------|\n",
    "| Nested Loops |  |  |\n",
    "| Optimized Loops |  | |\n",
    "| JIT Compilation |  |  |\n",
    "| PIL Library |  |  |\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Image arrays can be usefully filtered by 2D centered FIR filters:\n",
    "\n",
    "$$ y'_{i,j}=\\sum_{m=-m_1}^{m_1}\\sum_{n=-n_1}^{n_1}a_{m,n}y_{i,j}$$\n",
    "\n",
    "These filters can perform many different functions including blurring, sharpening and edge detection. The coefficient array $a_{m,n}$ is known as the filter \"kernel\", and has size $2m_1+1$ by $2n_1+1$. Filter kernels are usually square, with $m_1=n_1$. This filtering operation is known as 2D convolution.\n",
    "\n",
    "Edge detection is usually accomplished by smoothing (to remove image noise) and then applying a derivative operator. Further nonlinear operations can be used to refine the edges by suppressing weak edges, joining strong edges, etc. A commonly-used derivative kernel is the Sobel operator. For the horizontal (x) derivative, the Sobel operator is:\n",
    "\n",
    "$$ S_x= \\left[ \\begin{array}{ccc}\n",
    "-1 & 0 & 1 \\\\\n",
    "-2 & 0 & 2 \\\\\n",
    "-1 & 0 & 1 \\end{array} \\right]  $$\n",
    "\n",
    "and the vertical derivative uses the transpose $S_y=S_x^T$. These are simple extensions of the 1D 3-point stencil derivative operator from last week. The gradient magnitude of array $A$ is then $G=\\sqrt{(S_x * A)^2+(S_y * A)^2}$ where the $*$ symbol denotes 2D convolution and the square root is taken on each element of the array individually.\n",
    "\n",
    "Another commonly used filter kernel is the Laplacian ($\\nabla^2$) kernel\n",
    "\n",
    "$$ L = \\left[ \\begin{array}{ccc}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 4 & -1 \\\\\n",
    "0 & -1 & 0 \\end{array} \\right]  $$\n",
    "\n",
    "which detects second derivatives. This is sometimes used in image sharpening filters, which take the form\n",
    "\n",
    "$$ K = \\left[ \\begin{array}{ccc}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 \\end{array} \\right] +\\alpha L$$\n",
    "\n",
    "where the degree of sharpening can be controlled by $\\alpha$.\n",
    "\n",
    "Start by writing a general function to apply an arbitrary filter (2D convolution) of the type described above, and then answer the following questions. Your function may discard the edge points where the filter cannot be applied ($m_1$ points from each of the 2 edges in the first dimension and $n_1$ from the 2 edges in the second dimension).\n",
    "\n",
    "a. Load the mandrill image again, and perform a \"boxcar smoothing\" with a 15x15 kernel of the form $a_{m,n}=1/15^2$. Display the original and smoothed images.\n",
    "\n",
    "b. Load the \"peppers.png\" image and apply a 5x5 boxcar smoothing. Find the gradient magnitude $G$ using the Sobel operator on each channel (R,G,B) and sum them to get an overall gradient. Apply a threshold of 30% of the maximum gradient to discard weak edges (that is, if the gradient is less than 30% of the max, set the RGB values to 0,0,0 and otherwise set R,G,B=1,1,1). Plot the original image and the processed edges.\n",
    "\n",
    "c. Load the \"eye.png\" image and apply a Laplacian sharpening filter with kernel $K$ as given above and $\\alpha=0.3$ (moderate sharpening) and then with $\\alpha=3.0$ (extreme sharpening). This filter may cause some of the RGB values to go outside their nominal [0,1] range; they should be clipped to constrain the range. Plot the original image and the sharpened image for both values of $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_2d(img,kernel):\n",
    "    \"\"\"\n",
    "    docstring\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Load the image\n",
    "img = plt.imread('mandrill.png')\n",
    "\n",
    "# do stuff for 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Gradescope has difficulties with Jupyter notebooks larger than 1 MB. For this assignment, your notebook will almost certainly be larger than 1 MB, so please submit your work as a PDF file instead. To create a PDF from your Jupyter notebook:\n",
    "1.\tIf you’re using a JupyterLab environment (like syzygy), try selecting File -> “Save and Export Notebook As…”->PDF.\n",
    "2.\tIf you’re using Visual Studio Code, click the “…” (More Actions) at the top of the file editing window (beside “Outline”) and select “Export” and then “PDF”.\n",
    "3.\tIf you encounter trouble with exporting your PDF (which is not uncommon on many platforms), log into ucalgary.syzygy.ca, upload your .ipynb file and follow step 1.\n",
    "\n",
    "\n",
    "## Image sources\n",
    "\n",
    "Mandrill.png and peppers.png are standard test images from the USC Signal and Image Processing Institute available at  https://sipi.usc.edu/database/database.php?volume=misc .\n",
    "\n",
    "eyes.png is from the Wikipedia page for unsharp masking and is available at https://commons.wikimedia.org/wiki/File:Unsharped_eye.jpg. Image author is Ru_dragon, and the image is distributed under the GNU Free Documentation License.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
